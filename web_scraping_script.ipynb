{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Web Scraping Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library and Packages:\n",
    "\n",
    "- BeautifulSoup\n",
    "- Requests\n",
    "- os\n",
    "- time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\okori\\\\Documents\\\\Workspace'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the working directory for the project\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type in your desired job level and job category\n",
      "Filtering out job adverts with Junior Level and Full Time specifications:\n",
      "Filed saved: 17\n",
      "Filed saved: 28\n",
      "Waiting 10 minutes...\n"
     ]
    }
   ],
   "source": [
    "#importing the open source libraries and packages to be used for web scraping the web page\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Defining a function for this job web scraping script\n",
    "url = \"https://www.zippia.com/web-developer-tallahassee-fl-jobs/\" # creating a path to the HTML file with data hosted on the webpage\n",
    "\n",
    "# Using an input function to catch the filter criteria of end user\n",
    "print(\"Type in your desired job level and job category\")\n",
    "target_job_level = input('>') # The end user is prompted to enter their target job level (Senior Level, Junior Level, Entry Level, or Mid Level)\n",
    "target_job_category = input('>') # The end user is prompted to enter their target job category (Full Time, Part Time, or Internship)\n",
    "\n",
    "print(f\"Filtering out job adverts with {target_job_level} and {target_job_category} specifications:\")\n",
    "\n",
    "# Creating a function which holds the web scraping script (the entire code pulling information from the web page) and saves out the scrapped information to a text.\n",
    "def find_jobADS():\n",
    "    html_text = requests.get(url).text # A request is made to the website using the .get method of the request library to access and download the HTML data hosted on the webpage\n",
    "    soup = BeautifulSoup(html_text, 'html.parser') # Using the BeautifulSoup constructor, the soup is made by passing the path to the HTML file into a filehandle along with a HTML parser\n",
    "    jobs = soup.find_all('div', class_=\"d-flex col-10 col-sm-11 flex-column newJobSearchUI_card-content__nDbJ_ pl-2 pl-sm-4\") # BeautifulSoup .find_all method is used to find all div tags with the specified class in this line of code\n",
    "\n",
    "# The remaining lines of code finds and extracts specific information about each job posting on the web page\n",
    "    for index, job in enumerate(jobs):\n",
    "        span_tag = job.find(\"div\", class_=\"d-flex flex-wrap newJobSearchUI_job-tags__1WF6Y\").find_all('span')\n",
    "\n",
    "        for spantag in span_tag:\n",
    "            for tag in spantag:\n",
    "                #print(tag)\n",
    "                if tag in ('Senior Level', 'Junior Level', 'Mid Level', 'Entry Level'):\n",
    "                    job_level = tag.text.strip()\n",
    "                #print(job_level)\n",
    "\n",
    "                elif tag in ('Full Time', 'Part Time', 'Internship'):\n",
    "                    job_category = tag.text.strip()\n",
    "\n",
    "                elif tag in (\"Bachelors Preferred\", \"Bachelors Required\", \"High School Diploma Preferred\", \"Masters Preferred\", \"Masters Required\", \"Doctorate Preferred\", \"Associate Required\"):\n",
    "                    qualification = tag.text.strip()\n",
    "\n",
    "                else:\n",
    "                    job_level = \"job level not specified\"\n",
    "                    job_category = \"job category not specified\"\n",
    "                    qualification = \"qualification is not specified\"\n",
    "\n",
    "                job_title = job.find('h3', class_=\"newJobSearchUI_job-card--job-title__E68J0 mb-0 line-clamp-2\").text.replace(' (DAY 1 ON-SITE WORK)', '')\n",
    "                company_name = job.find('div', class_=\"newJobSearchUI_job-card--company-name__aoOaL\").text\n",
    "                job_specification = job.find('div', class_=\"newJobSearchUI_job-card--company-name__aoOaL newJobSearchUI_job-card--location__UGwfb\").text\n",
    "                brief_information = job.find('div', class_=\"lightTextStyle2 newJobSearchUI_job-description__pOQor\").text.replace('\\n', '')\n",
    "                payment_amount = job.find('div', class_=\"d-flex justify-content-between align-items-center newJobSearchUI_salary-postdate__mbHB9\").find('div', class_=\"newJobSearchUI_job-card--company-name__aoOaL newJobSearchUI_job-card--location__UGwfb\").text\n",
    "                date_of_job_post = job.find('div', class_=\"d-flex justify-content-between align-items-center newJobSearchUI_salary-postdate__mbHB9\").find('div', class_=\"d-block d-lg-none newJobSearchUI_job-card--company-name__aoOaL newJobSearchUI_job-card--location__UGwfb\").text\n",
    "\n",
    " # This lines of code uses the applies the filtering condition initiated by the end user at the beginning and writes informations generated about each job to a a separated file, storing each job details with an index of the job being iterated on    \n",
    "        if target_job_level == job_level and target_job_category == job_category:\n",
    "            with open(f\"jobadverts/{index}.txt\", 'w') as f:\n",
    "                f.write(f\"Job title: {job_title.strip()} \\n\")\n",
    "                f.write(f\"Company name: {company_name.strip()} \\n\")\n",
    "                f.write(f\"Job specification: {job_specification.strip()} \\n\")\n",
    "                f.write(f\"Brief information: {brief_information.strip()} \\n\")\n",
    "                f.write(f\"Payment amount: {payment_amount.strip()} \\n\")\n",
    "                f.write(f\"job level: {job_level} \\n\")\n",
    "                f.write(f\"Job category: {job_category} \\n\")\n",
    "                f.write(f\"qualification: {qualification} \\n\")\n",
    "                f.write(f\"Date of job posting: {date_of_job_post.strip()}\")\n",
    "\n",
    "            print(f\"Filed saved: {index}\")\n",
    "\n",
    "# This lines of code extends the program when the file is read directly and allows the program to run every 10 minutes\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        find_jobADS()\n",
    "        time_wait = 10\n",
    "        print(f'Waiting {time_wait} minutes...')\n",
    "        time.sleep(time_wait * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
